{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Train remotely in Azure Machine Learning\n",
    "\n",
    "The Iris dataset is often used in machine learning and data science courses, because itâ€™s simple to understand and well-defined, yet interesting enough to present real challenges to new learners. This tutorial will classify the Iris dataset into one of three flower species: Setosa, Versicolor, or Virginica.\n",
    "\n",
    "### What is the Iris dataset?\n",
    "The iris data consisted of 150 samples of three species of Iris. The first column represented sepal length, the second column represented sepal width, the third column represented petal length, and the fourth column represented petal width. I'm going to use sci-kit-learn to classify these instances according to their species of Iris, which will be distinguished based on their measurements. \n",
    "In fact, three of these iris species look similar, but the difference in measurements can be used to classify them. This data set is a classic example of supervised learning. The input variables are sepal length and width and petal length and width; each row represents an instance or observation. The output variable is Iris-setosa, Iris-versicolor, or Iris-virginica; each column represents a class label.\n",
    "\n",
    "The picture of the Iris species is given below:\n",
    "\n",
    "![Iris flower](../../media/iris_flowers.png \"Iris\")\n",
    "### Tutorial explanation\n",
    "In this tutorial we will use Azure ML with MLFlow to train a model for the iris dataset.\n",
    "We will:\n",
    "* Create a compute resource in Azure ML\n",
    "* Upload the dataset to Azure ML\n",
    "* Use the code in /src/main.py to train the model creating an experiment \n",
    "* Register the model using MLFlow\n",
    "\n",
    "## Set up the pipeline resources\n",
    "\n",
    "The Azure ML framework can be used from CLI, Python SDK, or studio interface. In this example, you'll use the AzureML Python SDK v2 to create a pipeline. \n",
    "\n",
    "Before creating the pipeline, you'll set up the resources the pipeline will use:\n",
    "\n",
    "* The dataset for training\n",
    "* The software environment to run the pipeline\n",
    "\n",
    "## Connect to the workspace\n",
    "\n",
    "Before we dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "SUBSCRIPTION_ID = os.getenv(\"SUBSCRIPTION_ID\") \n",
    "RESOURCE_GROUP = os.getenv(\"RESOURCE_GROUP\")\n",
    "AML_WORKSPACE_NAME = os.getenv(\"AML_WORKSPACE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1675966726847
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class WorkspaceHubOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=AML_WORKSPACE_NAME,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  or get compute\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_name = \"iris-cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute = ml_client.compute.get(cpu_compute_name)\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "    compute = AmlCompute(\n",
    "        name=cpu_compute_name, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset already exists. Name: Iris, version: 1\n"
     ]
    }
   ],
   "source": [
    "# create or get dataset\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# local filesystem\n",
    "data_asset_name = \"Iris\"\n",
    "my_path = \"./data/iris.csv\"\n",
    "# set the version number of the data asset\n",
    "v1 = \"1\"\n",
    "\n",
    "my_data = Data(\n",
    "    name=data_asset_name,\n",
    "    version=v1,\n",
    "    description=\"Iris data set\",\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    ")\n",
    "\n",
    "## create data asset if it doesn't already exist:\n",
    "try:\n",
    "    data_asset = ml_client.data.get(name=data_asset_name, version=v1)\n",
    "    print(\n",
    "        f\"Data asset already exists. Name: {my_data.name}, version: {my_data.version}\"\n",
    "    )\n",
    "except:\n",
    "    data_asset = ml_client.data.create_or_update(my_data)\n",
    "    print(f\"Data asset created. Name: {my_data.name}, version: {my_data.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "\n",
    "# define the command\n",
    "command_job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python main.py --iris-csv ${{inputs.iris_csv}} --learning-rate ${{inputs.learning_rate}} --boosting ${{inputs.boosting}}\",\n",
    "    environment=\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest\",\n",
    "    inputs={\n",
    "        \"iris_csv\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=data_asset.path,\n",
    "        ),\n",
    "        \"learning_rate\": 0.9,\n",
    "        \"boosting\": \"gbdt\",\n",
    "    },\n",
    "    compute=cpu_compute_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1675445030495
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/purple_battery_9wt86dfsmq?wsid=/subscriptions/ec967cb5-f2b0-43c2-9ba2-4a2eb94bbacc/resourcegroups/MLOps-demo-azureml/workspaces/modelops-demo-azureml&tid=16b3c013-d300-468d-ac64-7eda0820b6d3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "# get a URL for the status of the job\n",
    "returned_job.studio_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "run_model = Model(\n",
    "    path=\"azureml://jobs/{}/outputs/artifacts/paths/model/\".format(returned_job.name),\n",
    "    name=\"iris-remote-run-model-example\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL\n",
    ")\n",
    "\n",
    "ml_client.models.create_or_update(run_model)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Upload data to cloud storage, create a data asset, create new versions for data assets, use the data for interactive development."
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
